{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 Analysis - Argentina - 05/09/2020. (R Programming)"},{"metadata":{},"cell_type":"markdown","source":"### Import the necessary libraries for the analysis."},{"metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"cell_type":"code","source":"# This R environment comes with many helpful analytics packages installed\n# It is defined by the kaggle/rstats Docker image: https://github.com/kaggle/docker-rstats\n# For example, here's a helpful package to load\n\nlibrary(tidyverse) \nlibrary(forcats)\nlibrary(repr)\nlibrary(caret)\nlibrary(ROCR)\nlibrary(grid)\nlibrary(CatEncoders)\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nlist.files(path = \"../input/covidargentina/Covid19Casos.csv\")\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"covid <-  as.data.frame(read.csv('../input/covidargentina/Covid19Casos.csv',stringsAsFactors = FALSE, encoding = 'UTF-8'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 1 - Know the data"},{"metadata":{},"cell_type":"markdown","source":"### Let's take a look at the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to have a general overview about the data involved.\nglimpse(covid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see the provinces of Argentina and test types.\nunique(covid$residencia_provincia_nombre) \nunique(covid$clasificacion_resumen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now, let's modify a little bit the data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to translate some values to English...\ncovid$clasificacion_resumen[covid$clasificacion_resumen == 'Descartado'] <- 'Negative'\ncovid$clasificacion_resumen[covid$clasificacion_resumen == 'Sospechoso'] <- 'Suspicious'\ncovid$clasificacion_resumen[covid$clasificacion_resumen == 'Confirmado'] <- 'Confirmed'\ncovid$clasificacion_resumen[covid$clasificacion_resumen == 'Sin Clasificar'] <- 'Unclassified'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#... and change the dates format.\ncovid$fecha_apertura <- as.Date(covid$fecha_apertura)\ncovid$fecha_diagnostico <- as.Date(covid$fecha_diagnostico)\ncovid$fecha_inicio_sintomas <- as.Date(covid$fecha_inicio_sintomas, format = \"%Y-%m-%d\")\ncovid$ultima_actualizacion <- as.Date(covid$ultima_actualizacion, format = \"%Y-%m-%d\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.1 - Quantity of tests per province."},{"metadata":{"trusted":true},"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\nggplot(covid,aes(x = reorder(residencia_provincia_nombre,residencia_provincia_nombre,function(x)-length(x)),\n                             fill=factor(clasificacion_resumen))) +\n  geom_bar() +\n  scale_fill_brewer(palette = \"RdGy\")+\n  scale_y_continuous(labels = scales::comma, )+\n  coord_flip() +\n  ggtitle(\"Testing per Province\")+\n  xlab(\"Province\") +\n  ylab(\"Tests Quantity\") +\n  labs(fill = \"Status\") +\n  theme(legend.background = element_rect(fill = \"lightblue\",colour = \"grey50\",size = 1))\n       \n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 - Quantity of confirmed cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"confirmed <- as_tibble(covid %>%\n          filter(covid[\"clasificacion_resumen\"] == \"Confirmed\") %>%\n          count(residencia_provincia_nombre, sort = TRUE ))%>%\n          rename(Quantity_of_cases = n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"head(confirmed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"options(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\nggplot(confirmed, aes(y= Quantity_of_cases, x = reorder(residencia_provincia_nombre, desc(Quantity_of_cases)))) +\n geom_col(fill='blue') +\n scale_y_continuous(labels = scales::comma)+\n coord_flip() +\n ggtitle(\"Confirmed cases per Province\")+\n xlab(\"Province\") +\n ylab(\"Confirmed Cases Quantity\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3 - Evolution of cases through time."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we have to take a look if there are any missing information and format the dates.\nsum(is.na(covid$fecha_apertura))\nsum(is.na(covid$clasificacion_resumen))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's analyze the \"NA\" value.\nna_value <- covid %>% filter(is.na(covid$fecha_apertura) == TRUE)\nna_value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It seems that the value does not follow the structure of the rest of the dataset.\n# So, we can proceed with the plotting of the information. \n\noptions(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\nggplot(covid, aes(x = fecha_apertura ,fill = clasificacion_resumen ))+\n  geom_bar() +\n  scale_x_date(date_labels = \"%m-%Y\", date_break = \"1 month\" )+\n  scale_y_continuous(labels = scales::comma)+\n  ggtitle(\"Tests through time\")+\n  xlab(\"Month\") +\n  ylab(\"Quantity of tests\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.3.1 - Evolution of cases through time (without suspicious cases)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We are going to generate another dataset without the \"Suspicious\" cases\nnon_suspicious <- covid %>% filter(clasificacion_resumen != 'Suspicious')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# And let's plot it. \n\noptions(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\nggplot(non_suspicious, aes(x = fecha_apertura ,fill = clasificacion_resumen))+\n  geom_density(alpha = 0.25) +\n  facet_grid(clasificacion_resumen ~.)+\n  scale_x_date(date_labels = \"%m-%Y\", date_break = \"1 month\" )+\n  scale_y_continuous(breaks = c(0.01, 0.02), labels = c(\"10,000\", \"20,000\"))+\n  ggtitle(\"Confirmed cases through time\")+\n  xlab(\"Month\") +\n  ylab(\"Quantity of cases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.4 - Quantity of deaths through time."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Generate a new dataset only with deaths\ndeath <- covid %>% filter(fallecido == \"SI\")\n\n# And plot it.\noptions(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\nggplot(death, aes(x = fecha_apertura ,fill = fallecido))+\n  geom_density(alpha = 0.75) +\n  scale_x_date(date_labels = \"%m-%Y\", date_break = \"1 month\" )+\n  scale_y_continuous(breaks = c(0.0025, 0.005,0.0075,0.01,0.0125), labels = c(\"2,500\",\"5,000\",\"7,500\",\"10,000\",\"12,500\"))+\n  ggtitle(\"Deaths through time\")+\n  xlab(\"Month\") +\n  ylab(\"Quantity of cases\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 1.5 - Evolution of ventilators needed through time."},{"metadata":{"trusted":true},"cell_type":"code","source":"# New dataset only with the required ventilators\nventilator <- covid %>% filter(asistencia_respiratoria_mecanica == \"SI\")\n\n# Let's see the graph.\noptions(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\nggplot(ventilator, aes(x = fecha_apertura ,fill = asistencia_respiratoria_mecanica))+\n  geom_density(alpha = 0.75) +\n  scale_x_date(date_labels = \"%m-%Y\", date_break = \"1 month\" )+\n  scale_y_continuous(breaks = c(0.002, 0.004,0.006,0.008), labels = c(\"2,000\",\"4,000\",\"6,000\",\"8,000\"))+\n  ggtitle(\"Ventilators needed through time\")+\n  xlab(\"Month\") +\n  ylab(\"Quantity of ventilators needed\") +\n  scale_fill_brewer(palette = \"BuGn\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 2 - Data Preparation\n\n### Now we are going to prepare the data to run a logistic regression model in order to predict if people with certain characteristics will survive COVID or if they will not. "},{"metadata":{},"cell_type":"markdown","source":"### 2.1 - Creating a new dataset only with useful information."},{"metadata":{"trusted":true},"cell_type":"code","source":"# First of all, let's select only the relevant elements for the model and creat a new dataframe.\ncovid_analisis <- covid %>% select('fallecido',\n                                   'sexo',\n                                   'origen_financiamiento',\n                                   'asistencia_respiratoria_mecanica',\n                                   'edad') \nglimpse(covid_analisis)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# And let's change the characters values of our target for numbers.\ncovid_analisis$fallecido[covid_analisis$fallecido == 'NO'] <- 0\ncovid_analisis$fallecido[covid_analisis$fallecido == 'SI'] <- 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.2 - Taking a look at the NA's."},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have to analyze if there are NA's in our dataframe.\ncolSums(is.na(covid_analisis))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We have 1541 NA's in the \"edad\" field, as it does not represent a lot of cases compared with the rows of the entire dataframe, we will replace the NA's with the average. Otherwise, it will affect the model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace the NA's with the average.\nfor(i in 1:ncol(covid_analisis)){\n  covid_analisis[is.na(covid_analisis[,i]), i] <- mean(covid_analisis[,i], na.rm = TRUE)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's define all categorical values as factors and the age as interger.\ncovid_analisis$fallecido  <- as.factor(covid_analisis$fallecido)\ncovid_analisis$sexo <- as.factor(covid_analisis$sexo)\ncovid_analisis$origen_financiamiento <- as.factor(covid_analisis$origen_financiamiento)\ncovid_analisis$asistencia_respiratoria_mecanica  <- as.factor(covid_analisis$asistencia_respiratoria_mecanica)\ncovid_analisis$edad  <- as.integer(covid_analisis$edad)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.3 - Including the target in the \"x\" group and the variables in the \"y\" group. "},{"metadata":{"trusted":true},"cell_type":"code","source":"x <- 'fallecido'\ny <- c('sexo',\n       'residencia_provincia_nombre',\n       'origen_financiamiento',\n       'asistencia_respiratoria_mecanica',\n       'edad')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 2.4 - Splitting the datasets into train and test. "},{"metadata":{"trusted":true},"cell_type":"code","source":"# set seed for reproducibility\nset.seed(123)\n\n# making a train index\ntrain_index <- sample(c(TRUE, FALSE), replace = TRUE, size = nrow(covid_analisis), prob = c(0.2, 0.8))\n\n# split the data according to the train index\ntrain <- as.data.frame(covid_analisis[train_index, ])\ntest <- as.data.frame(covid_analisis[!train_index, ])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Part 3 - Modelling"},{"metadata":{},"cell_type":"markdown","source":"### 3.1 - Train the model."},{"metadata":{"trusted":true},"cell_type":"code","source":"model <- glm(fallecido ~ . , data = train, family = binomial(link = 'logit'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's take a look at the predictions.\noptions(repr.plot.width=15, repr.plot.height=10)\ntheme_set(theme_classic(base_size = 25))\n\n# make predictions on the test set\ntrain$pred <- predict(model, newdata=train, type=\"response\")\ntest$pred <- predict(model, newdata=test, type=\"response\")\n\n# plot histogram of predictions\ndata.frame(preds <- train$pred ) %>%\n    ggplot(aes(x = preds)) + \n    geom_histogram(bins = 50, fill = 'grey50') +\n    labs(title = 'Histogram of Predictions') \n\n# print range of predictions\nprint(round(range(train$pred),2))\n\n# print median of predictions\nprint(median(train$pred))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.2 - Exploring trade-off between precission and recall. "},{"metadata":{"trusted":true},"cell_type":"code","source":"predObj <- prediction(train$pred, train$fallecido)\nprecObj <- performance(predObj, measure=\"prec\")\nrecObj <- performance(predObj, measure=\"rec\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"precision <- (precObj@y.values)[[1]]\nprec.x <- (precObj@x.values)[[1]]\nrecall <- (recObj@y.values)[[1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rocFrame <- data.frame(threshold=prec.x, precision=precision,recall=recall)\nnplot <- function(plist) {\n                           n <- length(plist)\n                           grid.newpage()\n                           pushViewport(viewport(layout=grid.layout(n,1)))\n                           vplayout=function(x,y) {viewport(layout.pos.row=x, layout.pos.col=y)}\n                           for(i in 1:n) {\n                           print(plist[[i]], vp=vplayout(i,1))\n                                         }\n                          }\npnull <-mean(as.numeric(train$fallecido))\n\np1 <- ggplot(rocFrame, aes(x=threshold)) +\n      geom_line(aes(y=precision/pnull)) +\n      coord_cartesian(xlim = c(0,0.05), ylim=c(0,0.25) ) +\n      geom_vline(xintercept = 0.02, color=\"red\", linetype = 2)\np2 <- ggplot(rocFrame, aes(x=threshold)) +\n      geom_line(aes(y=recall)) +\n      coord_cartesian(xlim = c(0,0.05) ) +\n      geom_vline(xintercept = 0.02, color=\"red\", linetype = 2)\n\nnplot(list(p1, p2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Once we see the charts, we can conclude that 0.02 might be a good trade off. "},{"metadata":{},"cell_type":"markdown","source":"### 3.3 - Confusion matrix.\n[(Click for further information about this matrix)](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ctab.test <- table(pred=test$pred>0.02, fallecido =test$fallecido)\nctab.test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.3.4 - Precesion, recall and accuracy\n\n![](https://miro.medium.com/max/2400/1*uR09zTlPgIj5PvMYJZScVg.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"precision <- ctab.test[2,2]/sum(ctab.test[2,])\npaste(\"precision = \",precision)\n\nrecall <- ctab.test[2,2]/sum(ctab.test[,2])\npaste(\"recall = \",recall)\n\naccuracy <- (ctab.test[2,2]+ctab.test[1,1])/sum(ctab.test)\npaste(\"accuracy = \",accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.4 - ROC Curve. \n\n![](http://)[(Click here for further information)](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5)"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds <- predict(model, newdata = test, type = \"response\")\n\nroc_data <- data.frame(\n    p0.3 = ifelse(preds > 0.3, 1, 0),\n    p0.2 = ifelse(preds > 0.2, 1, 0),\n    p0.1 = ifelse(preds > 0.1, 1, 0),\n    p0.05 = ifelse(preds > 0.05, 1, 0),\n    p0.04 = ifelse(preds > 0.04, 1, 0),\n    p0.03 = ifelse(preds > 0.03, 1, 0),\n    p0.02 = ifelse(preds > 0.02, 1, 0),\n    p0.01 = ifelse(preds > 0.01, 1, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# true positive (hit) rate\ntpr <- function(pred, actual) {\n    res <- data.frame(pred, actual)\n    sum(res$actual == 1 & res$pred == 1) / sum(actual == 1)\n}\n\n# false positive rate\nfpr <- function(pred, actual) {\n    res <- data.frame(pred, actual)\n    sum(res$actual == 0 & res$pred == 1) / sum(actual == 0)\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"actual <- test$fallecido","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reshape to long format and get fpr and tpr for each threshold\nroc_data <- roc_data %>% \n    gather(key = 'threshold', value = 'pred') %>% \n    group_by(threshold) %>%\n    summarize(tpr = tpr(pred, actual = actual), \n              fpr = fpr(pred, actual = actual))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set x and y tick marks\nbreaks <-  c(0, 0.2, 0.4, 0.6, 0.8, 1)\n\n# get labels for plotting break points\nlabels <- substr(roc_data$threshold, start = 2, stop = 5)\n\n# plot the ROC curve\nggplot(data = roc_data, aes(x = fpr, y = tpr)) + \n    geom_line() + \n    geom_text(aes(label = labels), nudge_x = 0.05) + \n    geom_abline(intercept = 0, slope = 1, linetype = 'dashed') + \n    scale_x_continuous(limits = c(0, 1), breaks = breaks) + \n    scale_y_continuous(limits = c(0,1), breaks = breaks) + \n    labs(x = 'False Positive Rate', y = 'True Positive Rate', title = 'ROC Curve') ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 3.5 - Model Summary. "},{"metadata":{"trusted":true},"cell_type":"code","source":"summary(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Based on this information, we can conclude that the most significant parameters are:\n- Sex\n- asistencia_respiratoria_mecanica\n- Edad\n\nAlso, as the residual deviance is smaller than the null deviance, this tell us that the model works correctly. However, as we have 11 Fisher iterations, we can say that the algorithm has not converged. "},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"3.6.3"}},"nbformat":4,"nbformat_minor":4}